# -*- coding: utf-8 -*-
"""
Copy of CapsNet_Copy.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1YQmaM1EFkx9Bo72cdPqj-kWCwcfyVWwq
"""

from utils import *

class Conv1(nn.Module):
    def __init__(self, in_channels=1, out_channels=256, kernel_size=9, stride=1):
        super(Conv1, self).__init__()
        self.conv1 = nn.Sequential(nn.Conv2d(in_channels=in_channels,
                                             out_channels=out_channels,
                                             kernel_size=kernel_size,
                                             stride=stride),
                                   nn.ReLU()
                                  )
        
    def forward(self, x):
        a = self.conv1(x)
        return a

class PrimaryCaps(nn.Module):
    def __init__(self, num_capsules=32, grid_size=6 , in_channels=256, out_channels=8, kernel_size=9, stride=2, padding=0):
        super(PrimaryCaps, self).__init__()
        
        self.num_capsules = num_capsules
        self.grid_size = grid_size
        self.capsules = nn.ModuleList([
                        nn.Sequential(
                        nn.Conv2d(in_channels=in_channels,
                                  out_channels=num_capsules,
                                  kernel_size=kernel_size,
                                  stride=stride,
                                  padding=padding)
                                    ) for _ in range(out_channels)])
        
    def forward(self, x):
        self.grid_size = 6
        a = [capsule(x) for capsule in self.capsules]
        a = torch.stack(a, dim=1)
        a = a.view(a.shape[0], self.num_capsules*self.grid_size*self.grid_size, -1)
        return squash(a)

class DigitCaps(nn.Module):
    def __init__(self, num_capsules=10, num_routes=32*6*6, in_channels=8, out_channels=16, routing_iters=3):
        super(DigitCaps, self).__init__()
        
        self.num_capsules = num_capsules
        self.num_routes = num_routes
        self.routing_iters = routing_iters
        
        self.W = nn.Parameter(torch.randn(1, num_routes, num_capsules, out_channels, in_channels) * 0.01)
        self.bias = nn.Parameter(torch.rand(1, 1, num_capsules, out_channels) * 0.01)
        self.dot_update = nn.Parameter(torch.randn(1, num_routes, num_capsules, 1) * 0.01)
    
    def forward(self, x):
        # x: [batch_size, 1152, 8] -> [batch_size, 1152, 1, 8]
        #                          -> [batch_size, 1152, 1, 8, 1]
        primary_activations = torch.norm(x, dim=2, keepdim=False)
        x = x.unsqueeze(2).unsqueeze(dim=4)
        
        u_hat = torch.matmul(self.W, x).squeeze()  # u_hat -> [batch_size, 1152, 10, 16]
        
        #   b_ij = torch.zeros((batch_size, self.num_routes, self.num_capsules, 1))
        b_ij = Variable(x.new(x.shape[0], self.num_routes, self.num_capsules, 1).zero_())
        
        for itr in range(self.routing_iters):
            c_ij = func.softmax(b_ij, dim=2)
            s_j  = (c_ij * u_hat).sum(dim=1, keepdim=True) + self.bias
            v_j  = squash(s_j, dim=-1)
            
            if itr < self.routing_iters-1:
                a_ij = (u_hat * v_j).sum(dim=-1, keepdim=True)
                b_ij = b_ij + self.dot_update * a_ij
        v_j = v_j.squeeze().unsqueeze(-1)
        
        # returning digit_caps, routing_coefficients, primary_activations, prediction_activations
        return v_j, c_ij, primary_activations, torch.norm(u_hat, dim=3, keepdim=False)

class Decoder(nn.Module):
    def __init__(self, caps_size=16, num_caps=10, img_size=28, img_channels=1):
        super(Decoder, self).__init__()
        
        self.reconst_layers = nn.Sequential(
                                            nn.Linear(caps_size*num_caps, 512),
                                            nn.ReLU(inplace=True),
                                            nn.Linear(512, 1024),
                                            nn.ReLU(inplace=True),
                                            nn.Linear(1024, img_size*img_size*img_channels),
                                            nn.Sigmoid()
                                           )
        
        self.num_caps = num_caps
        self.img_channels = img_channels
        self.img_size = img_size
    
    
    def forward(self, x, target=None):
        if target is None:
            classes = torch.norm(x, dim=2)
            max_len_indices = classes.max(dim=1)[1].squeeze()
        else:
            max_len_indices = target.max(dim=1)[1]
        
        masked = x.new_tensor(torch.eye(self.num_caps))
        masked = masked.index_select(dim=0, index=max_len_indices.data)
        masked_output_tmp = (x * masked[:, :, None, None])
        masked_output = masked_output_tmp.view(x.shape[0], -1)
        reconst_output = self.reconst_layers(masked_output)
        reconst_output = reconst_output.view(-1, self.img_channels, self.img_size, self.img_size)
        return reconst_output, masked

class CapsNet(nn.Module):
    def __init__(self, cnn_in_channels=1, cnn_out_channels=256, cnn_kernel_size=9, cnn_stride=1,
                 pc_num_capsules=32, pc_grid_size=28, pc_in_channels=256, pc_out_channels=8, pc_kernel_size=9, pc_stride=2, pc_padding=0,
                 dc_num_capsules=10, dc_num_routes=32*6*6, dc_in_channels=8, dc_out_channels=16, dc_routing_iters=3,
                 dec_caps_size=16, dec_num_caps=10, dec_img_size=28, dec_img_channels=1):
        super(CapsNet, self).__init__()
        self.conv = Conv1(cnn_in_channels, cnn_out_channels, cnn_kernel_size, cnn_stride)
        self.pri_cap = PrimaryCaps(pc_num_capsules, pc_grid_size, pc_in_channels, pc_out_channels, pc_kernel_size, pc_stride, pc_padding)
        self.dig_cap = DigitCaps(dc_num_capsules, dc_num_routes, dc_in_channels, dc_out_channels, dc_routing_iters)
        self.dec_net = Decoder(dec_caps_size, dec_num_caps, dec_img_size, dec_img_channels)
        self.mse_loss = nn.MSELoss(reduction="none")
        
    def forward(self, x, target=None):
        output, c_ij, primary_activations, u_hat_activations = self.dig_cap( self.pri_cap( self.conv(x) ) )
        recnstrcted, masked_output = self.dec_net(output, target)
        return output, masked_output, recnstrcted, c_ij, primary_activations, u_hat_activations

